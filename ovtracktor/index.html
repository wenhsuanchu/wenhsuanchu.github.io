<!DOCTYPE html>
<html>
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-61302010-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-61302010-1');
    </script>
    <title>Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <!-- <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'> -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <style>
      html,body,h1,h2,h3,h4,h5,h6 {font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;}
      <!-- .cite { background:#f0f0f0; padding:10px; font-size:18px} -->
      .cite { padding:0px; background:#ffffff; font-size:18px}
      .card {border: 1px solid #ccc}
      img { margin-bottom:-6px;}
      p { font-size:18px;}
      a {text-decoration: none; color: #2196F3;}
      .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
      0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
      5px 5px 0 0px #fff, /* The second layer */
      5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
      10px 10px 0 0px #fff, /* The third layer */
      10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
      15px 15px 0 0px #fff, /* The fourth layer */
      15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
      20px 20px 0 0px #fff, /* The fifth layer */
      20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
      25px 25px 0 0px #fff, /* The fifth layer */
      25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
      margin-left: 10px;
      margin-right: 60px;
      }
    </style>
    <meta name="google-site-verification" content="8Q_ytX8FqHWcIDBc2IoJAwkJ35JRHclQw494GYdlHBE" />
  </head>  
  <body class="w3-white">
    <!-- Page Container -->
    <div class="w3-content w3-margin-top w3-margin-bottom" style="max-width:960px;">

      <!-- The Grid -->
      <div class="w3-row-padding">

	<!-- paper container -->	  
	<div class="w3-display-container w3-row w3-white w3-margin-bottom">
	  <div class="w3-center">
	    <h1>Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models</h1>
	    <h5><a href="https://wenhsuanchu.github.io/">Wen-Hsuan Chu</a> &emsp;&emsp; Adam W. Harley &emsp;&emsp; Pavel Tokmakov &emsp;&emsp; <br>
		    Achal Dave &emsp;&emsp; Leonidas J. Guibas &emsp;&emsp; Katerina Fragkiadaki</h5>
	    <!-- <h5><em>ECCV 2022 (Oral)</em></h5> -->
	  </div>
	  <div class="w3-center">
	    <h3>[Code (coming soon)] &emsp; <a href="https://arxiv.org/abs/2310.06992">Paper</a></h3>
	  </div>
	  <hr>

	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:10px;">
	    <tr style="padding:0px">
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<img style="width:100%;max-width:100%" alt="" src="images/horse-20.gif">
	      </td>
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<img style="width:100%;max-width:100%" alt="" src="images/davis_dogs.gif">
	      </td>
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<img style="width:100%;max-width:100%" alt="" src="images/robotap.gif">
	      </td>
	    </tr>
	  </table>
	  
	  <!-- <div class="w3-display-container w3-row w3-white w3-margin-bottom w3-center"> -->
	  <!--   <img src="images/fig1.png" style="width:100%"> -->
	  <!-- </div> -->
	  <hr>
	  <div class="w3-center">
	    <h2>Abstract</h2>
	  </div>
	  <p>Tracking-by-detection has long been a dominant paradigm for object tracking of specific object categories, such as people and vehicles. Recently, large-scale pre-trained models have shown promising advances in detecting and segmenting various types of objects and object parts in 2D images in the wild. This begs the question: can we re-purpose these large-scale pretrained static image detectors and segmenters to advance open-vocabulary video tracking? In this paper, we re-purpose an open-vocabulary detector, segmenter, and dense optical flow estimator, into a model that tracks and segments objects of any category in 2D videos. Given a monocular video input, our method predicts object and part tracks, with associated language descriptions. Our approach does not introduce any significant innovations: we propagate object boxes from frame to frame using an optical flow based motion model, we refine these propagated boxes with the box regression module of an open-vocabulary visual detector, and we prompt an open-world segmenter with the refined box to segment the box interior in a temporally consistent way. We decide the termination of an object track using forward-backward optical flow consistency, and re-identify using deep feature matching. We show that our model achieves strong performance on multiple established video object segmentation and tracking benchmarks, despite never being explicitly trained for tracking. We hope that our approach can serve as a simple and extensible framework for future research.</p>
	  <hr>
	  <div class="w3-display-container w3-row w3-white w3-margin-bottom w3-center">
	    <iframe width="800" height="600" src="https://www.youtube.com/embed/gNnE6elXcXA?autoplay=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
	  </div>
	  <hr>
	  <div class="w3-center">
	    <h2>Results</h2>
	  </div>
	  <p>For quantitative results, please check out the paper. Here we show some gifs on examples where the users can prompt the tracker to track specific object categories.</p>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:10px;">
	    <tr style="padding:0px">
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<div class="w3-center"><font size="+1"><strong>No prompts</strong></font></div> <br>
			<img style="width:100%;max-width:100%" alt="" src="images/davis_default.gif">
	      </td>
		  <br>
		  <td style="padding-right:1%;width:32%;vertical-align:middle">
			<div class="w3-center"><font size="+1"><strong>"Saddle"</strong></font></div> <br>
			<img style="width:100%;max-width:100%" alt="" src="images/davis_prompt.gif">
	      </td>
		</tr>
	  </table>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:10px;">
		<tr>
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<div class="w3-center"><font size="+1"><strong>No prompts</strong></font></div> <br>
			<img style="width:100%;max-width:100%" alt="" src="images/uvo_default.gif">
	      </td>
	      <td style="padding-right:1%;width:32%;vertical-align:middle">
			<div class="w3-center"><font size="+1"><strong>"Coffee Maker"</strong></font></div> <br>
			<img style="width:100%;max-width:100%" alt="" src="images/uvo_prompt.gif">
	      </td>
	    </tr>
	  </table>
	  <br>
	  <p>By swapping out the detector for a referential detector, OVTracktor can be easily extended for referential tracking.</p>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:10px;">
		<tr style="padding:0px">
			<td style="padding-right:1%;width:45%;vertical-align:middle">
				<div class="w3-center"><font size="+1"><strong>No prompts</strong></font></div> <br>
			    <img style="width:100%;max-width:100%" alt="" src="images/parachute_orig.gif">
			</td>
			<td style="padding-right:1%;width:45%;vertical-align:middle">
				<div class="w3-center"><font size="+1"><strong>"Large orange Parachute"</strong></font></div> <br>
			    <img style="width:100%;max-width:100%" alt="" src="images/parachute_grounded.gif">
			</td>
		</tr>
	  </table>
	  <br>
	  <p>Since the detector is run at all frames, care must be taken when querying for "position-based" entities. In this example, the "rightmost" person changes as people move in the scene, leading to 2 final tracks.</p>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:10px;">
	  	<tr style="padding:0px">
			<td style="padding-right:1%;width:45%;vertical-align:middle">
				<div class="w3-center"><font size="+1"><strong>No prompts</strong></font></div> <br>
			    <img style="width:100%;max-width:100%" alt="" src="images/rightmost_orig.gif">
			</td>
	  		<td style="padding-right:1%;width:45%;vertical-align:middle">
				<div class="w3-center"><font size="+1"><strong>"Rightmost person"</strong></font></div> <br>
			    <img style="width:100%;max-width:100%" alt="" src="images/rightmost_grounded.gif">
			</td>
		</tr>
	  </table>
	  <hr>

	  <div class="w3-row w3-margin" style="padding-bottom:2em">
	    <div class="w3-center"><h2>Paper</h2></div>
	    <div class="w3-col s0 m1 l2" style="height:10px"></div>
	    <div class="w3-col s6 m3 l2">
			<img class="layered-paper-big" src="images/p1_paper.png" style="width:100%;min-height:200px; margin-right:3em">
	    </div>
	    <div class="w3-col s6 m7 l6" style="padding-left:5em">
	      <div class="cite">
		Wen-Hsuan Chu, Adam W. Harley, Pavel Tokmakov, Achal Dave, Leonidas J. Guibasm and Katerina Fragkiadaki.
		<i>Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models</i> 
	      </div>
	      <h3><a href="https://arxiv.org/pdf/2310.06992.pdf">[pdf]</a>&emsp;<a href="bib.txt">[bibtex]</a></h3>
	    </div>
	    <div class="w3-col s0 m1 l2" style="height:10px"></div>
	  </div>
	  <hr>
	  
	  <!-- end paper container -->

	</div><!-- End Grid -->
      </div><!-- End Page Container -->

  </body>
</html>
